<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Publication | Runmin Jiang’s Homepage</title>
    <meta name="description" content="The description of the site.">
    <link rel="icon" href="photo.jpg">
    
    <link rel="preload" href="/assets/css/0.styles.91fcb47a.css" as="style"><link rel="preload" href="/assets/js/app.856886af.js" as="script"><link rel="preload" href="/assets/js/2.63d7f518.js" as="script"><link rel="preload" href="/assets/js/10.9c0aceac.js" as="script"><link rel="preload" href="/assets/js/5.ccd09fff.js" as="script"><link rel="prefetch" href="/assets/js/11.73363121.js"><link rel="prefetch" href="/assets/js/12.c03877d0.js"><link rel="prefetch" href="/assets/js/13.2ec344fa.js"><link rel="prefetch" href="/assets/js/14.107b964c.js"><link rel="prefetch" href="/assets/js/15.cd12a966.js"><link rel="prefetch" href="/assets/js/16.c15a5446.js"><link rel="prefetch" href="/assets/js/17.29da4c15.js"><link rel="prefetch" href="/assets/js/3.072c80fb.js"><link rel="prefetch" href="/assets/js/4.4d10d8ef.js"><link rel="prefetch" href="/assets/js/6.da35c38b.js"><link rel="prefetch" href="/assets/js/7.c9def93b.js"><link rel="prefetch" href="/assets/js/8.cbaf21bf.js"><link rel="prefetch" href="/assets/js/9.675cb8d0.js">
    <link rel="stylesheet" href="/assets/css/0.styles.91fcb47a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar projects-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Runmin Jiang’s Homepage</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/publication/" class="nav-link router-link-exact-active router-link-active">Publication</a></div><div class="nav-item"><a href="/award/" class="nav-link">Awards</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/publication/" class="nav-link router-link-exact-active router-link-active">Publication</a></div><div class="nav-item"><a href="/award/" class="nav-link">Awards</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="publication">Publication</h1> <div class="md-card show-border"><!----> <div class="card-content"><p style="font-family:'Georgia', serif;font-weight:bold;font-size:22px;">Enhancing Weakly Supervised 3D Medical Image Segmentation through Probabilistic-aware Learning</p> <p><strong>Co-first Author</strong>. Currently under review for <em>International Conference on Learning Representations (<a href="https://iclr.cc/Conferences/2024" target="_blank" rel="noopener noreferrer">ICLR2024<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>)</em> which has an <strong>H5 index of 303</strong> and is <strong>ranked #10</strong> on <a href="https://scholar.google.com/citations?view_op=top_venues" target="_blank" rel="noopener noreferrer">Google Scholar<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <p><strong>Abstract</strong>: 3D medical image segmentation is a challenging task with crucial implications for disease diagnosis and treatment planning. Recent advances in deep learning have significantly enhanced fully supervised medical image segmentation. However, this approach heavily relies on labor-intensive and time-consuming fully annotated ground-truth labels, particularly for 3D volumes. To overcome this limitation, we propose an innovative probabilistic-aware weakly supervised learning pipeline tailored for 3D medical image segmentation. Our pipeline consists of three key components. Firstly, we introduce a Probability-based Pseudo Label Generation scheme that synthesizes dense 3D segmentation masks from sparsely annotated point annotations. Secondly, we develop a Probabilistic Multi-head Self-Attention network to extract robust probability-driven features, forming the foundation of our Probabilistic Transformer Network. Lastly, we incorporate a Probability-informed Segmentation Loss Function that effectively  guides the training process by incorporating annotation confidence. Experimental results demonstrate significant improvements in weakly supervised segmentation, surpassing state-of-the-art methods.</p> <img src="/projects/framework.png" alt="Framework Image" style="display:block;width:105%;margin:15px auto;"></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p style="font-family:'Georgia', serif;font-weight:bold;font-size:22px;">How Effective and Robust is Sentence-Level Data Augmentation for Named Entity Recognition?</p> <p><strong>Runmin Jiang</strong>†, Xin Zhang, Jiyue Jiang, Wei Li, Yuhao Wang. <br></p> <p>In <em>CCF International Conference on Natural Language Processing and Chinese Computing <strong>(NLPCC)</strong></em>, 2022. <strong>[Oral]</strong></p> <p><a href="https://dl.acm.org/doi/10.1007/978-3-031-17120-8_5" target="_blank" style="color:#1A65C0;background-color:#FFFFFF;padding:3px 6px;text-align:center;text-decoration:none;display:inline-block;border:1px solid #1A65C0;border-radius:8px;margin-right:5px;">ACM</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-17120-8_5" target="_blank" style="color:#1A65C0;background-color:#FFFFFF;padding:3px 6px;text-align:center;text-decoration:none;display:inline-block;border:1px solid #1A65C0;border-radius:8px;margin-right:5px;">Springer</a></p> <p><strong>Abstract</strong>: Data augmentation is a simple but effective way to improve the effectiveness and the robustness of pre-trained models. However, they are difficult to adapt to token-level tasks such as named entity recognition (NER) because of the different semantic granularity and more fine-grained labels. Inspired by some mixup augmentations in computer vision, we proposed three sentence-level
data augmentations including CMix, CombiMix, TextMosaic, and adapted them to the NER task. Through empirical experiments on three authoritative datasets (OntoNotes4, CoNLL-03, OntoNotes5), we found that these methods will improve the effectiveness of the models if controlling the number of augmented samples. Strikingly, the results show our approaches can greatly improve the robustness of
the pre-trained model even over strong baselines and token-level data augmentations. We achieved state-of-the-art (SOTA) in the robustness evaluation of the CCIR CUP 2021.</p> <img src="/projects/mosaic.png" alt="Mosaic Image" style="display:block;width:70%;margin:15px auto;"></div></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.856886af.js" defer></script><script src="/assets/js/2.63d7f518.js" defer></script><script src="/assets/js/10.9c0aceac.js" defer></script><script src="/assets/js/5.ccd09fff.js" defer></script>
  </body>
</html>
